ğŸ¯ Exam Failure Analysis & Early Risk Detection ğŸ“‰ğŸ“
ğŸ“Œ Project Overview

Educational institutions often identify students after they fail exams, leaving little scope for timely intervention.
This project analyzes academic and behavioral data to detect students at risk of exam failure early, enabling proactive academic support.

The focus is on explainable, metric-driven analysis rather than black-box prediction models.

ğŸ¯ Problem Statement

Students fail exams due to a combination of factors such as:

Poor attendance

Low internal assessment scores

Inconsistent study habits

History of past academic failures

However, these indicators are often analyzed in isolation.
This project combines multiple measurable signals to systematically identify failure risk before exams occur.

ğŸ¯ Objectives

Analyze key factors contributing to exam failure

Identify at-risk students using clear, interpretable rules

Support early academic intervention through data insights

ğŸ“‚ Dataset Description

The dataset represents student performance over a semester and includes academic, behavioral, and contextual attributes.

ğŸ”‘ Key Features

attendance_pct â€“ Percentage of classes attended

internal_marks â€“ Internal assessment scores

assignment_score â€“ Assignment performance

study_hours â€“ Average daily study hours

past_failures â€“ Number of previous exam failures

exam_score â€“ Final exam score

failure_risk â€“ Target variable (Yes / No)

ğŸ› ï¸ Tech Stack & Tools

Python

Pandas â€“ Data cleaning and manipulation

NumPy â€“ Numerical operations

Matplotlib & Seaborn â€“ Data visualization

Jupyter Notebook

Git & GitHub

ğŸ” Methodology

Data cleaning and validation

Feature engineering

Exploratory Data Analysis (EDA)

Rule-based risk classification

Insight generation using visualizations

ğŸ“ Failure Risk Classification Logic

A student is classified as At Risk if any of the following conditions apply:

â€¢ Exam score < 40
â€¢ Attendance < 65%
â€¢ Internal marks < 35
â€¢ Past failures â‰¥ 2


This approach ensures transparency and interpretability, making results easy to understand for non-technical stakeholders.

ğŸ“Š Exploratory Data Analysis

The analysis includes:

Pass vs Fail distribution

Attendance vs exam performance

Study hours vs exam score

Impact of past failures

Correlation heatmap of numerical features

ğŸ’¡ Key Insights

Low attendance is strongly associated with exam failure

Internal assessments are reliable predictors of final outcomes

Students with prior failures face significantly higher risk

Consistent study habits reduce failure probability

âš ï¸ Limitations

Rule-based logic (no machine learning model used)

Limited dataset size

No real-time academic tracking

ğŸš€ Future Enhancements

Machine learningâ€“based failure prediction

Faculty dashboard for monitoring risk

Integration with Learning Management Systems (LMS)

Automated early warning alerts

ğŸ“ Project Structure
exam-failure-analysis/
â”‚
â”œâ”€â”€ exam_data.csv
â”œâ”€â”€ failure_analysis.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

â–¶ï¸ How to Run the Project

Clone the repository

Open failure_analysis.ipynb in Jupyter Notebook

Run the cells sequentially

ğŸ’¼ Use Case

Academic risk monitoring

Student performance analytics

Education-focused data analysis projects

ğŸ‘¤ Author

Ekansh Jain
Aspiring Data Analyst / Intern

â­ Conclusion

This project demonstrates how simple, explainable data analysis can help institutions identify exam failure risk early and support better academic outcomes.
